{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import random\n",
    "import markovify\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Форматирование текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        raw = f.read()\n",
    "    raw = raw.lower()\n",
    "    raw = re.sub(r'[^а-яА-Я.!?…\\n]+', ' ', raw)\n",
    "    raw = re.sub(r'\\n+', '\\n', raw)\n",
    "    return re.sub(r' +', ' ', raw)\n",
    "\n",
    "def get_vocab(text):\n",
    "    res = []\n",
    "    rev = {}\n",
    "    for c in text:\n",
    "        if c not in res:\n",
    "            rev[c] = len(res)\n",
    "            res.append(c)\n",
    "    return rev, res\n",
    "\n",
    "def encode(s, remap):\n",
    "    return [remap[c] for c in s]\n",
    "\n",
    "def div(spltd, max_len):\n",
    "    res = []\n",
    "    for spl in spltd:\n",
    "        spl += '.'\n",
    "        res += [spl[i:i+max_len] for i in range(0, len(spl), max_len)]\n",
    "    return res\n",
    "\n",
    "maxlen = 80\n",
    "bsize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 460172\n",
      "Vocab power: 38\n"
     ]
    }
   ],
   "source": [
    "zar = get_text('zaratustra.txt')\n",
    "print('Text length:', len(zar))\n",
    "voc, revoc = get_vocab(zar)\n",
    "count = len(revoc)\n",
    "print('Vocab power:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I really tried but it all only got bad things\n",
    "# splitted = re.split(r'[\\?\\!\\.…]+', zar)\n",
    "# splitted = div(splitted, maxlen)\n",
    "# splitted = filter(lambda x: len(x) != 0, zar.split())\n",
    "# splitted = [encode(s, voc) + [voc[' ']] for s in splitted]\n",
    "# splitted[:5]\n",
    "# maxlen = max(map(len, splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1,  2, ...,  8,  4,  6],\n",
       "        [ 1,  2,  3, ...,  4,  6,  7],\n",
       "        [ 2,  3,  4, ...,  6,  7, 15],\n",
       "        ...,\n",
       "        [17, 14,  6, ...,  6, 20, 15],\n",
       "        [14,  6,  7, ..., 20, 15,  9],\n",
       "        [ 6,  7,  8, ..., 15,  9, 26]], dtype=int32),\n",
       " (460091, 81))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filled = sequence.pad_sequences(splitted, maxlen=maxlen+1, value=voc[' '])\n",
    "# filled = np.array(encode(zar, voc))\n",
    "filled = []\n",
    "for i in range(0, len(zar) - maxlen - 1, 1):\n",
    "    filled.append(encode(zar[i:i+maxlen+1], voc))\n",
    "filled = sequence.pad_sequences(filled, maxlen=maxlen+1, value=voc[' '])\n",
    "filled, filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 80), (128, 80)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(filled.reshape((-1,)))\n",
    "sequences = char_dataset.batch(maxlen+1, drop_remainder=True)\n",
    "\n",
    "def splt(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(splt)\n",
    "\n",
    "dataset = dataset.shuffle(1000).batch(bsize, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO more logic for arch\n",
    "def build_model(vocab_size, batch_size):\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(vocab_size, 64, batch_input_shape=[batch_size, None]),\n",
    "        layers.LSTM(256, return_sequences=True, stateful=True),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='chpts_one/{epoch}', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, length, randomness):\n",
    "    start = encode(start_string, voc)\n",
    "    start = tf.expand_dims(start, 0)\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    model.reset_states()\n",
    "    i = 0\n",
    "    while (True):\n",
    "        predictions = model(start)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        predictions *= randomness\n",
    "        \n",
    "        predicted_id = tf.math.argmax(predictions, axis=1)[-1]\n",
    "        predicted_random_shit = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        # print(encode(tf.math.argmax(predictions, axis=1), revoc))\n",
    "        # print(tf.random.categorical(predictions, num_samples=1)[-1,0]) # [-1,0].numpy()\n",
    "\n",
    "        \n",
    "        start = tf.expand_dims([predicted_random_shit], 0)\n",
    "\n",
    "        result.append(revoc[predicted_random_shit])\n",
    "        # result += encode(predicted_ids, revoc)\n",
    "        \n",
    "        # print(len(result), result[-1])\n",
    "        i += 1\n",
    "        if (i >= length and result[-1] in ['.', '!', '?', '…']) or (i >= length * 1.5):\n",
    "            break\n",
    "\n",
    "    return (start_string + ''.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (128, None, 64)           2432      \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (128, None, 256)          328704    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (128, None, 256)          0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (128, None, 38)           9766      \n",
      "=================================================================\n",
      "Total params: 340,902\n",
      "Trainable params: 340,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(len(voc), bsize)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, more = 0, 50\n",
    "model.fit(dataset, initial_epoch=i, epochs=i+more, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch_model = build_model(len(voc), 1)\n",
    "sbatch_model.load_weights(tf.train.latest_checkpoint('chpts'))\n",
    "sbatch_model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "заратустра сказал бы своего вернулся еще с полночным и еще оставался о высшие люди как я услыхал хочет вечности мои свой воскликнул он с полночным и любви подобно моей  хочет моей вещей мои сострадание хочет мне и потом его в себя самый пещере своим сердце своем и полночь теперь себя самого всех сегодня о заратустра в сердце своем и простил себе себя на себя самих себя с полночным и полночь меня в себя самого своего сказал он в сердце своем и цели с поыснился с восклезном делало ли вы не ! \n",
      "как еще слишком много своего и от всех вещий друг так велики стали вы высшие люди стал по высшие люди на которой уни в последний человек в полночь мое сострадание не заратустра и лицо свой полдень и хочет домой приближается о высшие люди мне не отвечал самый безобразный человек но еще совершенно пространовился ? \n",
      " \n",
      "большом у любовь к нему и сказал заратустра и слово своей  головой справидали о как между вечер своего долго более простите в лицо свой из своего и сам самого своего вернул он совершенно подобно меня не простил себе себя и полночь скорбь молчал и подобно меня не созидающие и простил себе мои счастье и глубокий при для меня в сердце своем и полночь теперь себя и не простил себе себя самого своего и своей себя мои с! в .\n",
      " \n",
      " полночно более приносил себя самого всех полночь не могил свое слова своего и стал он высшие люди сказал с воскледнем последний человек о высшие люди сказал он радость должен был бы они стали вы не и подобно моей сердце всегда своего фели мои высшие люди мне сердце свое время и йто себя он более прийти в это смеяться с ьечности своего не простил себе себя самого крик о этом с толпа и призрак он все время крик с глубокий глубокий призрак о высшие люди сказал свое сердце своем должен раз подобно меня разве любили в себя самого своего воспоминает меня не подобно меня подобно меня все вы стал бы я шем и все воздух как теперь все время как бы чем вечно может скорбь и крик мой свой воскликнул он у меня сердце его вещи и любил он сказал заратустра и сострадали вокруг себя самое простительности и принимает меня мое сострадание как между своему и не стал он высшие люди все высоты сходит это сегодня усталость стал головою и скорбь не своей сердце своем и полночь теперь себя самого всех сил своего сердца ли вы мое сострадание как меня ?\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(sbatch_model, 'заратустра сказал', 2000, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(map(lambda x: list(x + '.'), re.split(r'[\\?\\!\\.…]+', zar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "самым что и если б не бойкие души. \n",
      "никогда прежде чем моим духе ваша волосы.  ну что лгут .  как тешила ли похожим назначения которые пристыженные подумал он с тобой тени его ограбил. \n",
      "даже тюрьму. \n",
      "но род род при этом оно глаза.  \n",
      "пусть вашу любовь и наравнение горит добродетель.  \n",
      "последние своей добродетели.  двигать это.  вознести их.  куча беремени низкий из любви так охотишься тем кто сумрака много у них .  о том что однажды от тебя.  но том его смеялась я смотрите числу паразить добре и жалкие мое \n",
      " хотел я себе братья мои.  какое нибудь более жаждут сидит наших людям .  поступать вас не среди подобных баловней и от чрезмерно бороду служим также ведомые света между двух которыми ядовитыми ходил к нему недостаточно для чего смирению когда присоедино. \n",
      "пиявки лежала их мачтах почествовалась сердитесь от мир сзади них негодующий. \n",
      "ты называли бы мне самого вы какой также ушел месяца в придется к пучины глупостью \n",
      " о заратустра танцор ветер душ называет . \n",
      "все и для отдохновение его слишком глубок как верблюду которых жил несчастье давно всегда будет к чем ты истекай кроткий машущий ключ и называть даже в третий разрушительным также возмог себя на пересоздает знаешь сам с такие чтобы тебя в женщине сокрытом мест и не жид. \n",
      "они не сдерживались народа не любящий хотел разбились день говорить человека и недостойной \n",
      "томились мне нравятся опять лет не хотел бы что мы узнан я теперь это знаю ты скорбь.  но теперь та изобретения ступеней сегодня глаза. \n",
      "вы совершают от всякая вещах церковь. \n",
      " о чему до конца.  о благорода слава оному кто не вторично остановящееся ко мне было спасите своего. \n",
      "или они зову тебя.  спросился новых мук.  также дольшей вышел я никогда когда оставь мне дурно учение.  брат мой право напало великих людей . \n",
      "поистине браком высота есть твое есть лицо на одной мяч теперь учил что создают со всему только свидеть и в больных. \n",
      "теперь пожирается в свет.  созидать молчание.  остает их от богатый молчал.  \n",
      "но он любите земля хорошо угадываемой и заратустра. \n",
      "братья мои. \n",
      "и я в ней и дурна.  она все что я так хочет жить неведомым призраки \n",
      " как. \n",
      "кровища по девичьей дороги в сторону мира не забываешь заратустра ответило ли хочет другое о высечь розгами. \n",
      "все что они отныне сомнений. \n",
      "но я сладостно над чем все приятнее сжиматься не пощекотать прибывшегося не умеет священные мудрец с грустью.  разве ты также и этом возвращается цель все кто эти горим и одиночество.  воскликнул глаза видетельно на пути .  там слепца и ради тебя. \n",
      " \n",
      "о волгали за эту игру слова и визжат перед и великий хазар нашего бремя вокруг меня вопросы и вот избавление добавитель привязывать голов огня чем фасад их волковатым удачно всю руку которых не изучились кричал он и глядеть \n",
      "обоих волю но себе правдивца но недостаточно сильных искусанный прошло.  друг он учились на вновь рассматриваю я тебя молния прошел к этим жалкие люди.  мрачные свое возмездие на чтобы он хочет он рассказывать им лица.  посмотрящим чист для дикая бабочек великие поэтому более морях и я умел бы гордостигли этом как похожи самый тихий час похожи на своей жизни не умеете рычал прохлады. \n",
      "вы не научилась бы угадывают господа по девичьей добра и лавок. \n",
      "набожный и постоянно на своими крутится освежает в твою голод напасть. \n",
      "скрижали в отвечал для тебя в презренное значит лишь хрипевшие таки проходит познавать в тик так говорил заратустра всех сверкает он владевает свыше их как воля и ценность этих свой свирелью надутый целое.  давно происходит и как раскрыла глубок с земле. \n",
      "они происхождение мое \n",
      " в полдень этим.  \n",
      " час мой радовавшийся с помолочной оставая она того возьми обманчиво теряют они делало уста который тяжести \n",
      "тебе новому глотку и свобождает отречетесь харкать а всех вокруг который вековом заглянул он как не смотрите же мог радость и народы падает новая зима злая подобно ему еще земной человек слишком должен упасть.  то и что любишь меня на сегодняшнего у них приносить их горшкам у который учит со всегда пошел по белокурым\n",
      "чудовище по которая есть в ваших от избавительные теплых жаб. \n",
      "так говорят они воля львы должны руки противны они находит нас худым и новые ценного.  не от мира. \n",
      "но каждому и опрокисло все вы князья. \n",
      "лежу бессильных.  славия чтобы они войнам.  заратустра. \n",
      "но я ищу своею все изменилось ли ты хочет слишком стеклянных полночь тихо придает маленьких людей.  последнее. \n",
      "но скорби ваших подтачивать познаваемый врага.  следят за то полный ты спеть судьбою и скрежет и старого снова застывшим над ваших даже это противен то же показал он наконец подобных ему тела и ложь образие ветры. \n",
      "и так что услышал я не долго с разве я говорить отвратить.  иначе ибо я подобно соединяло сюда слышу заратустра я презрение. \n",
      "о вы лжем слабости.  и тут они это говорят в ваших мисках. \n",
      "быть море и зло до тогда узнать во всего давно ужасающая полночным. \n",
      "сказав этом гневом веселый муки. \n",
      "это о затем страдания моей и восходит это еще раз опьяняющей руки.  когда отвращение.  \n",
      "так проводы \n",
      "если бы он был при двор и вздохи сидело его самый тяжести.  возражают ее.  выжги им всего жил своих. \n",
      "эти наравнении сорным многих навострит птицей ему научились день перед тобой прошли на всякая речью надутый благословлять. \n",
      "но им проклинаю я в грязь бросит любовь должно было вседовольных чем злое человек.  поистине друг к другу мы лгать так одином зеркалом\n",
      "полет по моей спин овец я уже от маленькими но еще кричало меня так научиться в города настолюбцев или тебя предпринимаете. \n",
      "и остановлениями и почему глупец тот которых и привлекать утерянных себя. \n",
      "ибо он с горбатому что я сын свое ожидали некогда ты должны бы вы настолько для моя мы не говорил заратустрой.  тогда с соседа если бы следующий от отребье. \n",
      "и вот смысл.  опаснеешь. \n",
      "ночь \n",
      " ах его имеет тот мира. \n",
      "и недоверчиво тащишь меня. \n",
      "и даже когда умирающие и близко видеть одиноким.  ах. \n",
      "и не дружбу с глаза заглянулся кричит всякого дня уснувшее.  о ближнему.  что правдивца но только устал чародей\n",
      " \n",
      "но разучитесь нечто чуть бы он даже ночи.  в грудь жестче.  и кто бы ты говорить легло на прорывает тебя я к истоптать с раскромный желудок. \n",
      "но даже свои жирные влюблено потонуть среди люди них способным кажется на эти два \n",
      " в качества с ложа на расскажу я только глубине дурно говорилась я с гневом а солнца нашел бы я что есть сидел вниз как море расточать и поистине.  таковы ибо еще до того кто проклятья и двенадцать легкое нибудь вы друзья угадавший год подал заратустра смеялся я говорит ко мне даже тело холодной или трухой сторонниками и смотрели действительно. \n",
      "но куда бежит мне эти выступы сказал заратустра обрели хлебные теснился ребенка. \n",
      "но для тело оно подвижная благородный и сотрясение. \n",
      "и недоверие что я повстречу мне касается ваша ложью и смехом и своих сперва оценку впервым и самым безумие что за которых улицу пусть будут они думает даже когда ты не смеет обо мною и ленивец.  и также и поистину.  идем.  и мы знаем уже давно потому они всякое пламя ревнивающий к высокой велика.  так говоришь ты и темных дерева ковчега. \n",
      "даже когда самого безумствам.\n"
     ]
    }
   ],
   "source": [
    "chain = markovify.Chain(corpus=corpus, state_size=5)\n",
    "chain.compile()\n",
    "print(' '.join([''.join(chain.walk()) for _ in range(100)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
